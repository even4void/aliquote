+++
title = "Computer Age Statistical Inference"
date = 2018-10-06T19:04:51+01:00
draft = false
tags = ["review", "statistics"]
categories = ["2018"]
+++

Back in March I started to review the latest book authored by [Bradley Efron](http://statweb.stanford.edu/~ckirby/brad/) and [Trevor Hastie](https://web.stanford.edu/~hastie/), *Computer Age Statistical Inference*. Since then I found that there are far better reviews than the one I could write right now, and it is probably time to close this post or just [let it go](https://www.rousette.org.uk/archives/getting-things-done-by-letting-things-go/). 

<!--more-->

> Statistics is the science of learning from experience, particularly experience that arrives a little bit at a time.

Together with the [Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/) or an [Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/), this is another great reference for applied researchers. The present book shares a similar spirit in that it offers a deep review of modern techniques of statistical inference, especially in Part 2, but it also covers more "classical" techniques like generalized linear and time to event models. Note that the book has also been made [available in PDF format](https://web.stanford.edu/~hastie/CASI/) for free. 

As I said above, there are many good reviews of this book on the internet, including one by [Joseph Rickert](https://rviews.rstudio.com/2016/10/28/book-review-computer-age-statistical-inference/) and another one by [William J. Satzer](https://www.maa.org/press/maa-reviews/computer-age-statistical-inference) on the MAA. So I will let the interested reader go through these reviews and read the whole book. For what is worth, chapters 4, 7, 10, 17 and 20 are my preferred ones, although I learned a lot from the last chapter which is all about the empirical Bayes learning process.

From the very beginning of the book, the authors want to pinpoint and exploit the distinction that one can establish "between the algorithmic and inferential aspects of statistical analysis." For example, while averaging a series of observed numbers is an algorithm, computing the standard error of this estimate allows to make an inference for the accuracy of this algorithm. I like the idea of the interplay between statistical algorithm and learning because it sums up the situation of computational statistics very well. Nowadays, there are so many schools of thought to focus on ([machine learning vs. statistics](http://www.fharrell.com/post/stat-ml/), [data scientists vs. statisticians](https://twitter.com/josh_wills/status/198093512149958656)) that such pragmatic distinction should help to (somewhat) decide where to put one's effort.

While editing this draft post, I found the following link at the end of the post. I don't remember why I put this when I was in draft mode, but in case someone find it useful, I will leave it there but don't ask me why: [Do Statistical Methods Have an Expiration Date?](http://andrewgelman.com/2018/04/11/statistical-methods-expiration-date-talk-noon-mon-16-apr-university-pennsylvania/)

{{% music %}}John Cale â€¢ *Fragments of a Rainy Season*{{% /music %}}
