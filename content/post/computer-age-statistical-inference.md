+++
title = "Computer Age Statistical Inference"
description = ""
date = 2018-02-12T19:04:51+01:00
draft = true
tags = ["review", "statistics"]
categories = []
+++

Today, I will discuss the latest book authored by [Bradley Efron](http://statweb.stanford.edu/~ckirby/brad/) and [Trevor Hastie](https://web.stanford.edu/~hastie/), *Computer Age Statistical Inference*. Note that the book has been made [available in PDF format](https://web.stanford.edu/~hastie/CASI/) for free. 

<!--more-->

The introduction follows the classical distinction between *estimation*, based on a regression framework using least squares with asymptotic standard errors or lowess fit with 95% bootstrap CIs, and *hypothesis testing* on a set of candidate genes in the leukemia data set, that the authors used to illustrate the two-sample Student t-test and the false-discovery rate approach to multiple testing.

Chapter 2 is about frequentist inference, and it provides a concise albeit very ponctillous summary of key concepts in the frequentist approach. Basically, 

Whereas the preceding chapters focused on


The book makes heavy use of the R statistical software, which is great since it is open source and the reader can follow along every example with no pain.